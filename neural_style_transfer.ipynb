{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b144ec",
   "metadata": {},
   "source": [
    "# Neural Style Transfer\n",
    "\n",
    "**Reference:** [Gatys, L. A., Ecker, A. S., & Bethge, M. (2016). Image Style Transfer Using Convolutional Neural Networks. CVPR.](https://doi.org/10.1109/CVPR.2016.265)\n",
    "\n",
    "**Objective:** Implement the neuron style transfer algorithm described in the reference paper using Jittor deeplearning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b570b24",
   "metadata": {},
   "source": [
    "## Setup code\n",
    "Some boilerplate code to set up our environment before getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f606fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2399d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # set default size of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ee4a2",
   "metadata": {},
   "source": [
    "## Load pre-trained model\n",
    "We use VGG-16 to do the style transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from jittor.models.vgg import *\n",
    "\n",
    "# use the pre-trained version\n",
    "model = vgg16(pretrained=True)\n",
    "x = jt.rand(1, 3, 224, 224)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794a28d",
   "metadata": {},
   "source": [
    "Run below to get detailed model structure info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f37998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print vgg16 model structure\n",
    "print(model.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82adad",
   "metadata": {},
   "source": [
    "## Neuron style transfer algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5189a0e",
   "metadata": {},
   "source": [
    "**Target Feature Computation**\n",
    "\n",
    "A custom `VGGFeatureExtractor` class is used to obtain feature maps from specific layers of the VGG network.  \n",
    "\n",
    "By passing image through this extractor, we obtain the **content features** and **style features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c61116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_style_transfer import VGGFeatureExtractor\n",
    "\n",
    "# Define the default layers to extract content and style features:\n",
    "# - Content features are extracted from layer relu4_2 (index 20) to capture high-level image structure\n",
    "# - Style features are extracted from layers relu1_1, relu2_1, relu3_1, relu4_1, relu5_1\n",
    "#   (indices 1, 6, 11, 18, 25) to capture multi-scale texture and style information\n",
    "content_layer = 20 \n",
    "style_layers = [1, 6, 11, 18, 25] \n",
    "\n",
    "# Initialize feature extractor with specific layers\n",
    "extractor = VGGFeatureExtractor(model, content_layer, style_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67eafd",
   "metadata": {},
   "source": [
    "**Image Synthesis Initialization**\n",
    "\n",
    "The synthesis image is initialized as **a clone of the content image**.  \n",
    "It is set to require gradients so that it can be iteratively optimized using backpropagation.\n",
    "\n",
    "**Optimization Loop**  \n",
    "\n",
    "We aim to minimize the total loss which equals **content loss** computed by `compute_content_loss`, **style loss** computed by `compute_style_loss` and **tv loss** computed by `compute_tv_loss`.\n",
    "\n",
    "In neural style transfer, the content loss and style loss measure how well the generated image preserves the original content and matches the target style, respectively. In addition to these two objectives, we also include a total variation (TV) loss, which acts as a regularizer that encourages smoothness in the generated image by reducing unnecessary noise and artifacts.\n",
    "\n",
    "**Post-processing and Visualization**\n",
    "\n",
    "Denormalize the final image to convert it back to the standard RGB range.  \n",
    "\n",
    "Display the final stylized image and plot loss curves to monitor convergence.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from jittor import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_style_transfer import (\n",
    "    preprocess, deprocess,\n",
    "    compute_content_loss, compute_style_loss, compute_tv_loss,\n",
    ")\n",
    "\n",
    "def style_transfer(\n",
    "    content_image_path,\n",
    "    style_image_path,\n",
    "    saved_path=None,       #  do not save if None\n",
    "    content_weight=1e0,\n",
    "    style_weight=1e7,\n",
    "    tv_weight=1e-6,\n",
    "    learning_rate=0.3,\n",
    "    num_steps=500,\n",
    "    max_width=512,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform neural style transfer from style_image onto content_image.\n",
    "    \n",
    "    Args:\n",
    "        content_image_path (str): Path to content image.\n",
    "        style_image_path (str): Path to style image.\n",
    "        saved_path (str or None): Path to save the final image. If None, do not save.\n",
    "        content_weight (float): Weight for content loss.\n",
    "        style_weight (float): Weight for style loss.\n",
    "        tv_weight (float): Weight for total variation loss.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        num_steps (int): Number of iterations.\n",
    "        max_width (int): Resize content image to this width (maintaining aspect ratio).\n",
    "    \"\"\"\n",
    "\n",
    "    # GPU auto detect\n",
    "    jt.flags.use_cuda = 1 if jt.has_cuda else 0\n",
    "\n",
    "    # ---------------------------\n",
    "    # Load images\n",
    "    # ---------------------------\n",
    "    content_image = preprocess(content_image_path, max_width)\n",
    "    style_image = preprocess(style_image_path, max_width)\n",
    "    \n",
    "    # Extract features\n",
    "    target_content_rep, _ = extractor(content_image)\n",
    "    _, target_style_rep = extractor(style_image)\n",
    "\n",
    "    # Initialize synthesis image\n",
    "    image_synthesis = content_image.clone().stop_grad()\n",
    "    image_synthesis.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam([image_synthesis], lr=learning_rate)\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        synth_content_rep, synth_style_rep = extractor(image_synthesis)\n",
    "\n",
    "        # Compute losses\n",
    "        content_loss = compute_content_loss(synth_content_rep, target_content_rep)\n",
    "        style_loss = compute_style_loss(synth_style_rep, target_style_rep)\n",
    "        tv_loss = compute_tv_loss(image_synthesis)\n",
    "\n",
    "        total_loss = content_weight * content_loss + style_weight * style_loss + tv_weight * tv_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.step(total_loss)\n",
    "\n",
    "        # 打印日志\n",
    "        if step % 50 == 0 or step == num_steps - 1:\n",
    "            print(f\"Step {step}: Total Loss {total_loss.item():.4f}, \"\n",
    "                  f\"Content {content_loss.item() * content_weight:.4f}, \"\n",
    "                  f\"Style {style_loss.item() * style_weight:.4f}, \"\n",
    "                  f\"TV {tv_loss.item() * tv_weight:.4f}\")\n",
    "\n",
    "    final_image = deprocess(image_synthesis)\n",
    "    plt.imshow(final_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # ---------------------------\n",
    "    # auto save final image（optional）\n",
    "    # ---------------------------\n",
    "    if saved_path is not None:\n",
    "        final_image.save(saved_path)\n",
    "        print(f\"Final image saved to {saved_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993c023",
   "metadata": {},
   "source": [
    "## Generate some pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ec6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'content_image_path': 'images/tubingen.jpg',\n",
    "    'style_image_path': 'styles/starry_night.jpg',\n",
    "    'saved_path': None,\n",
    "    'content_weight': 1e0, \n",
    "    'style_weight': 1e7,\n",
    "    'tv_weight': 1e-5,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_steps': 500,\n",
    "    'max_width': 512\n",
    "}\n",
    "\n",
    "style_transfer(**parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
